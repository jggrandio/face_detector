{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1589b3ed-e75a-41c9-b788-b9ed915c4457",
   "metadata": {},
   "outputs": [],
   "source": [
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f4fb877-ddf2-4575-ba34-e150b043fd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = 'data/full_images'\n",
    "faces_path = 'data/faces'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b804b1f9-b6c9-4881-b155-850bfc8e3ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create face detection pipeline to get face samples from bigger images\n",
    "mtcnn = MTCNN()\n",
    "\n",
    "# Create an inception resnet (in eval mode):\n",
    "resnet = InceptionResnetV1(pretrained='vggface2').eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e3e5c16-c11a-437f-924d-e4d77c0b2e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take all the images and cut the face\n",
    "for image_name in os.listdir(images_path):\n",
    "    img = Image.open(os.path.join(images_path,image_name))\n",
    "    # Get cropped image tensor\n",
    "    img_cropped = mtcnn(img, save_path=os.path.join(faces_path,image_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8912601c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take sample image and calculate embeddings\n",
    "cos_sim = torch.nn.CosineSimilarity()\n",
    "sample_img = Image.open(os.path.join(faces_path,os.listdir(faces_path)[8]))\n",
    "convert_tensor = T.ToTensor()\n",
    "emb_sample = resnet(convert_tensor(sample_img).unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7c32c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6042], grad_fn=<SumBackward1>)\n",
      "tensor(0.8897, grad_fn=<CopyBackwards>)\n",
      "\n",
      "tensor([0.6206], grad_fn=<SumBackward1>)\n",
      "tensor(0.8711, grad_fn=<CopyBackwards>)\n",
      "\n",
      "tensor([0.6797], grad_fn=<SumBackward1>)\n",
      "tensor(0.8004, grad_fn=<CopyBackwards>)\n",
      "\n",
      "tensor([0.9138], grad_fn=<SumBackward1>)\n",
      "tensor(0.4153, grad_fn=<CopyBackwards>)\n",
      "\n",
      "tensor([0.9079], grad_fn=<SumBackward1>)\n",
      "tensor(0.4292, grad_fn=<CopyBackwards>)\n",
      "\n",
      "tensor([0.6400], grad_fn=<SumBackward1>)\n",
      "tensor(0.8485, grad_fn=<CopyBackwards>)\n",
      "\n",
      "tensor([0.8032], grad_fn=<SumBackward1>)\n",
      "tensor(0.6274, grad_fn=<CopyBackwards>)\n",
      "\n",
      "tensor([0.8133], grad_fn=<SumBackward1>)\n",
      "tensor(0.6111, grad_fn=<CopyBackwards>)\n",
      "\n",
      "tensor([1.0000], grad_fn=<SumBackward1>)\n",
      "tensor(0., grad_fn=<CopyBackwards>)\n",
      "\n",
      "tensor([0.6135], grad_fn=<SumBackward1>)\n",
      "tensor(0.8792, grad_fn=<CopyBackwards>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Measure similarities and distance against the sample image\n",
    "for image_name in os.listdir(faces_path):\n",
    "    \n",
    "    img = Image.open(os.path.join(faces_path,image_name))\n",
    "    img_embedding = resnet(convert_tensor(img).unsqueeze(0))\n",
    "    \n",
    "    # Calculate similarity\n",
    "    sim = cos_sim(emb_sample,img_embedding)\n",
    "    dist = (emb_sample - img_embedding).norm()\n",
    "    print(sim)\n",
    "    print(dist)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "612cc562af43790af71926c76e3268a121b3c535764cc6df78be4bcf9c493aa5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
